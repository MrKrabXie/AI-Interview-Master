
功能点需求：

1. 除了这个功能可以考虑加一个对于场景手册的分析， 和原理思考题分析的功能， --这个功能的意义在于。 提出问题比解决问题更加重要

2. 干， 我的爬虫被禁了一天 ， 爬虫有毒， 果然得多加一点随机时间的机制， a.触发验证码， 还有b.验证码打码问题。

3. 分析问题语义相似度， 毕竟有很多不同源的问题， 将其分析出来，列出来成列表， 然后进行我们可选项的替换， 还有配置相似度在95以上的直接的删掉活跃权重低的问题

4. 加入手动收集的问题
5. 加入反馈机制， 就是AI回答 与 原回答 选哪一个
6. 加入提出问题的机制 --选出超前的书籍， 包括软考的题目， 使其提出问题和答案， 让用户去使用， 进行投票。--也就是引入反馈， 定期进行更新
7. 用户测试界面 ， 界面要简单， 并且好用， 目前设想是 一个问题， 然后两个选择题语音机制（答案很长很难说文字写完）
8. 初始化界面， 选择对应的标签， 选择水平程度， 希望了解的技术栈。
9. 重新打分机制。--如果错误率太多， 会降级到其它水平从而进行重新回答
10. 需要一个表， 得保存下用户对于ai_answer汇集表的答案选择  --算是日志表吧
11. 目前的模式通过真确答案和AI答案进行比对， 大家都是挖掘者或者监督者， 但如果增加错误选择， 可以让大家变成做题者。

需求点的来源思想：
1. 数据的过滤器：人选题， 人是顶级思考， 用他们（高手）作为过滤的测试者， 
2. 数据来源：答案和题目是采用网络收集的方式， 前沿的内容用论文和英文书籍内化的方式。
3. 数据的价值： 人的投票和搜索机制， 进行投票， 根据标签的关注程度， 和题目本身的等级，和标签， 进行分类， 从而制定学习程度
4. 关于实际方案的考量： 原来的大家题目都是偏学术， 人称八股文， 我们需要对它进行场景化假设， 在这种高场景下进行假设推理和演变。
5. 面试不同的厂商： 对应不同的厂商会有不同的回答模式， 偏业务的， 和偏系统，算法， 校招的面试官的画像是不一样的， 
所以需要不同的智能体， 需要给它安排一个不同的智能体， 这样去适配大家的回答， 不同行业也会导致不同的区别， 基于此也要做出区别来
6. 

未来设想：
1. 如果能有一个架构虚拟环境的游戏， 让大家进行操作， 学习。  包括架构方案的制定， 技术栈的制定， 测试压力情况的推理 --使得大家可以用一个地方进行测算和演变 